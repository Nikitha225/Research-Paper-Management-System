{
    "page_1": {
        "paragraph_0": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Arabian Journal for Science and Engineering"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "https://doi.org/10.1007/s13369-017-3018-9"
            }
        },
        "paragraph_1": {
            "line_0": {
                "font_size": 9,
                "bold": false,
                "text": "R E S E A R C H A R T I C L E - S Y S T E M S E N G I N E E R I N G"
            }
        },
        "paragraph_2": {
            "line_0": {
                "font_size": 16,
                "bold": false,
                "text": "Fuzzy Q-Learning-Based Multi-agent System for Intelligent Trafﬁc"
            },
            "line_1": {
                "font_size": 16,
                "bold": false,
                "text": "Control by a Game Theory Approach"
            }
        },
        "paragraph_3": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Abolghasem Daeichian1 · Amir Haghani2"
            }
        },
        "paragraph_4": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Received: 11 December 2015 / Accepted: 3 December 2017"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "© King Fahd University of Petroleum & Minerals 2017"
            }
        },
        "paragraph_5": {
            "line_0": {
                "font_size": 10,
                "bold": true,
                "text": "Abstract"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "This paper introduces a multi-agent approach to adjust trafﬁc lights based on trafﬁc situation in order to reduce average delay"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "time. In the trafﬁc model, lights of each intersection are controlled by an autonomous agent. Since decision of each agent"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "affects neighbor agents, this approach creates a classical non-stationary environment. Thus, each agent not only needs to"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "learn from the past experience but also has to consider decision of neighbors to overcome dynamic changes of the trafﬁc"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "network. Fuzzy Q-learning and Game theory are employed to make policy based on previous experiences and decision of"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "neighbor agents. Simulation results illustrate the advantage of the proposed method over ﬁxed time, fuzzy, Q-learning and"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "fuzzy Q-learning control methods."
            }
        },
        "paragraph_6": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "Keywords Trafﬁc control · Multi-agent system · Game theory · Fuzzy Q-learning"
            }
        },
        "paragraph_7": {
            "line_0": {
                "font_size": 12,
                "bold": true,
                "text": "1 Introduction"
            }
        },
        "paragraph_8": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "Urbanization, increasing number of vehicles, and lack of"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "transport infrastructures have increased travel time, fuel con-"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "sumption, and air pollution. Therefore, urban life equals with"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "waste of time, less clean air, and acoustic pollution. Con-"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "ventional ﬁxed trafﬁc management systems are not able to"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "ﬁght complexity and dynamic of large trafﬁc networks. While"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "artiﬁcial intelligence (AI) are greatly employed to develop"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "intelligent trafﬁc systems (ITS) [6,7,19,24], multi-agent sys-"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "tem is an approach to model ITS [25,30]. This framework"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "consists of a population of intelligent and autonomous agents"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "work together in an environment [27]. Trafﬁc lights [20],"
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "vehicles [3], and pedestrians [29] are considered as agents"
            },
            "line_12": {
                "font_size": 10,
                "bold": false,
                "text": "in modeling of urban trafﬁc networks. Each agent needs"
            },
            "line_13": {
                "font_size": 10,
                "bold": false,
                "text": "to learn from the past experiences which is a key point to"
            },
            "line_14": {
                "font_size": 10,
                "bold": false,
                "text": "approximate a better decision-making policy. Multi-agent"
            },
            "line_15": {
                "font_size": 10,
                "bold": false,
                "text": "model-based [32] as well as model-free [12] reinforcement"
            },
            "line_16": {
                "font_size": 10,
                "bold": false,
                "text": "learning (RL) techniques are widely used in researches on"
            },
            "line_17": {
                "font_size": 10,
                "bold": false,
                "text": "ITS [6,23]."
            }
        },
        "paragraph_9": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "B Abolghasem Daeichian"
            }
        },
        "paragraph_10": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "a-daeichian@araku.ac.ir; a.daeichian@gmail.com"
            }
        },
        "paragraph_11": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1 Department of Electrical Engineering, Faculty of"
            }
        },
        "paragraph_12": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Engineering, Arak University, Arak 38156-8-8349, Iran"
            }
        },
        "paragraph_13": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "2 Department of Electrical Engineering, Payam Institute of"
            }
        },
        "paragraph_14": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Higher Education, Golpayegan, Isfahan, Iran"
            }
        },
        "paragraph_15": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "In a multitude of researches, any agent only considers its"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "own trafﬁc state in order to determine the control policy."
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "For example, single intersection with two phases is investi-"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "gated in [2]. Length of vehicles queue waiting on the light"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "is considered as state which can be measured by the agent. It"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "decides on extend green time or change it to the next phase so"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "that the number of vehicles waiting on the light is minimized."
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "The results show superiority of Q-learning agent over uni-"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "form trafﬁc ﬂows and constant-ratio trafﬁc ﬂows. In [32],"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "trafﬁc lights are considered as agents which communicate"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "with vehicles. The vehicles estimate their mean waiting time"
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "and transmit this time to trafﬁc light where a popular RL"
            },
            "line_12": {
                "font_size": 10,
                "bold": false,
                "text": "algorithm, namely Q-learning, is used to provide a control"
            },
            "line_13": {
                "font_size": 10,
                "bold": false,
                "text": "for trafﬁc signal scheduling. Results of this study show 22%"
            },
            "line_14": {
                "font_size": 10,
                "bold": false,
                "text": "reduction in waiting time compared to constant time lights."
            },
            "line_15": {
                "font_size": 10,
                "bold": false,
                "text": "Multi-objective reinforcement learning is utilized to control"
            },
            "line_16": {
                "font_size": 10,
                "bold": false,
                "text": "several trafﬁc lights in [17]. Optimization goals include num-"
            },
            "line_17": {
                "font_size": 10,
                "bold": false,
                "text": "ber of stops of a vehicle, mean stopping time, and length of"
            },
            "line_18": {
                "font_size": 10,
                "bold": false,
                "text": "vehicles’ queue on the next intersection. Its results indicate"
            },
            "line_19": {
                "font_size": 10,
                "bold": false,
                "text": "that multi-RL can effectively prevent the queue spillovers"
            },
            "line_20": {
                "font_size": 10,
                "bold": false,
                "text": "under congested condition to avoid large-scale trafﬁc jams."
            },
            "line_21": {
                "font_size": 10,
                "bold": false,
                "text": "Bull et al. [10] used learner classiﬁers to control light traf-"
            },
            "line_22": {
                "font_size": 10,
                "bold": false,
                "text": "ﬁc including 4 intersections. In this research, trafﬁc lights"
            },
            "line_23": {
                "font_size": 10,
                "bold": false,
                "text": "include two phases at each intersection, where one phase is"
            },
            "line_24": {
                "font_size": 10,
                "bold": false,
                "text": "for moving north–south and one is for east-west. Controller"
            },
            "line_25": {
                "font_size": 10,
                "bold": false,
                "text": "at each intersection obtains optimum phase time through"
            },
            "line_26": {
                "font_size": 10,
                "bold": false,
                "text": "extracting if-then rules. Its results show that performance of"
            }
        },
        "paragraph_16": {
            "line_0": {
                "font_size": 15,
                "bold": false,
                "text": "123"
            }
        },
        "paragraph_17": {},
        "paragraph_18": {},
        "paragraph_19": {},
        "paragraph_20": {},
        "paragraph_21": {},
        "paragraph_22": {},
        "paragraph_23": {},
        "paragraph_24": {},
        "paragraph_25": {},
        "paragraph_26": {},
        "paragraph_27": {},
        "paragraph_28": {},
        "paragraph_29": {},
        "paragraph_30": {},
        "paragraph_31": {},
        "paragraph_32": {},
        "paragraph_33": {},
        "paragraph_34": {},
        "paragraph_35": {},
        "paragraph_36": {},
        "paragraph_37": {},
        "paragraph_38": {},
        "paragraph_39": {},
        "paragraph_40": {},
        "paragraph_41": {},
        "paragraph_42": {},
        "paragraph_43": {},
        "paragraph_44": {},
        "paragraph_45": {},
        "paragraph_46": {},
        "paragraph_47": {},
        "paragraph_48": {},
        "paragraph_49": {},
        "paragraph_50": {},
        "paragraph_51": {},
        "paragraph_52": {},
        "paragraph_53": {},
        "paragraph_54": {},
        "paragraph_55": {},
        "paragraph_56": {},
        "paragraph_57": {},
        "paragraph_58": {},
        "paragraph_59": {},
        "paragraph_60": {},
        "paragraph_61": {},
        "paragraph_62": {},
        "paragraph_63": {},
        "paragraph_64": {},
        "paragraph_65": {},
        "paragraph_66": {},
        "paragraph_67": {},
        "paragraph_68": {},
        "paragraph_69": {},
        "paragraph_70": {},
        "paragraph_71": {},
        "paragraph_72": {}
    },
    "page_2": {
        "paragraph_0": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "the trafﬁc light using learner classiﬁer system has improved"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "signiﬁcantly compared to constant time trafﬁc light. In [28],"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "the learning purpose is modeled in such a way that states"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "indications are based on the summation of the cars wait-"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "ing times. Obviously, the more cars information is received,"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "the model will be more complicated and state space will be"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "larger. This issue is one of the signiﬁcant problems of large"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "networks. Adaptive control, which is introduced in [23],"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "uses the approximate of a function as mapping of states to"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "scheduling. Fuzzy inference engine is exploited to decrease"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "systematic faults of Q-algorithm in [22]. The results demon-"
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "strate that not only learning in fuzzy framework is done faster"
            },
            "line_12": {
                "font_size": 10,
                "bold": false,
                "text": "than Q-learning but also delay in intersections is decreased"
            },
            "line_13": {
                "font_size": 10,
                "bold": false,
                "text": "considerably. A multi-agent fuzzy approach is proposed in"
            },
            "line_14": {
                "font_size": 10,
                "bold": false,
                "text": "[18], where Q-learning updates the set of rule base in fussy"
            },
            "line_15": {
                "font_size": 10,
                "bold": false,
                "text": "inference engine. In [13], a new method which has the capa-"
            },
            "line_16": {
                "font_size": 10,
                "bold": false,
                "text": "bility to estimate an incomplete model of environment is"
            },
            "line_17": {
                "font_size": 10,
                "bold": false,
                "text": "described for a given non-static environment. This method"
            },
            "line_18": {
                "font_size": 10,
                "bold": false,
                "text": "is applied in a network composed of 9 intersections. The"
            },
            "line_19": {
                "font_size": 10,
                "bold": false,
                "text": "reported results show that this method has better performance"
            },
            "line_20": {
                "font_size": 10,
                "bold": false,
                "text": "than the model-free methods and model-based methods, but"
            },
            "line_21": {
                "font_size": 10,
                "bold": false,
                "text": "could not be generalized and used in larger networks."
            }
        },
        "paragraph_1": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "In other researches, agents consider other agents in"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "determination of their own control policy. For instance, coor-"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "dination among agents is desired in [21] where the agents not"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "only consider number of waiting vehicles on its own inter-"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "section, but also they consider number of vehicles which"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "have stopped in adjacent intersections. The RL is applied"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "on 5 intersections within three different scenario. The over-"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "all results show improvement in delay time. In [32], RL is"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "used to control the trafﬁc in a grid where a type of cooper-"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "ative learning simultaneously controls the trafﬁc signals and"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "determines the optimal routes. One of the main drawbacks"
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "of this method is the high costs of communication and infor-"
            },
            "line_12": {
                "font_size": 10,
                "bold": false,
                "text": "mation exchange, speciﬁcally when intersections of network"
            },
            "line_13": {
                "font_size": 10,
                "bold": false,
                "text": "are increased. Cooperative RL tries to extract the knowledge"
            },
            "line_14": {
                "font_size": 10,
                "bold": false,
                "text": "from neighbor agents in a scheduling learning [26]. This"
            },
            "line_15": {
                "font_size": 10,
                "bold": false,
                "text": "method is implemented in an area of Dublin including 64"
            },
            "line_16": {
                "font_size": 10,
                "bold": false,
                "text": "intersections."
            }
        },
        "paragraph_2": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "This paper introduces a hybrid fuzzy Q-learning and Game"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "theory method for control of trafﬁc lights in multi-agent"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "framework. It exploits the beneﬁts of fuzziﬁcation as well as"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "interaction with other agents. The trafﬁc network is modeled"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "by considering an autonomous agent controls in which each"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "intersection decides on duration of green phase. The number"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "of vehicles in different inputs of the intersection are mea-"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "sured by the corresponding agent. Any agent interacts with"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "neighbor agents by getting a reward from each decision. This"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "paper proposes that each agent fuzzify the inputs and utilizes"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "in a fuzzy inference system for fuzzy estimation of trafﬁc"
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "model states. The agent uses a Q-learning approach modi-"
            },
            "line_12": {
                "font_size": 10,
                "bold": false,
                "text": "ﬁed by Game theory to learn from the past experiences and"
            },
            "line_13": {
                "font_size": 10,
                "bold": false,
                "text": "consider the interaction with neighbor agents. The agent gets"
            }
        },
        "paragraph_3": {
            "line_0": {
                "font_size": 15,
                "bold": false,
                "text": "123"
            }
        },
        "paragraph_4": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Arabian Journal for Science and Engineering"
            }
        },
        "paragraph_5": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "a reward proportional to its own trafﬁc state and a reward from"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "each decision from neighbor agents to update its Q-learning"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "algorithm. The neighbor reward and its weighting in Q-value"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "update is proposed to be fuzzy in the proposed method. The"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "proposed method is applied on a ﬁve-intersection trafﬁc net-"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "work. The simulation results indicate that proposed method"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "outperforms the ﬁxed time, fuzzy, Q-learning and fuzzy Q-"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "learning control methods in the sense of average delay time."
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "This paper is unfolds as follows. After this introduction,"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "Q-learning and its fuzzy version are described in the next"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "section. Section 3 is devoted to application of Game theory"
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "in ITS. Sections 4 and 5 are about problem statement and"
            },
            "line_12": {
                "font_size": 10,
                "bold": false,
                "text": "proposed solution, respectively. Simulation results are given"
            },
            "line_13": {
                "font_size": 10,
                "bold": false,
                "text": "in Sect. 6. Finally, the paper is concluded in Sect. 7."
            }
        },
        "paragraph_6": {
            "line_0": {
                "font_size": 12,
                "bold": true,
                "text": "2 Q-Learning and Fuzzy Q-Learning"
            }
        },
        "paragraph_7": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "The objective of agents which act in dynamic environments"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "is making optimum decisions. If the agents are not aware of"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "rewards corresponding to various actions, selecting a proper"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "action would be challenging. To achieve this goal, learning"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "adjusts agents’ action selection based on collected data. Each"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "agent tries to optimize its actions with dynamic environment"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "via trial and error in reinforcement learning (RL). The RL is"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "actually how different situations are mapped upon actions to"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "receive the best results or the highest reward. In many cases,"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "actions inﬂuence the reward of next steps as well as affect the"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "reward of its corresponding step. There are model-based [32]"
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "as well as model-free [12] RL techniques. In model-free RL,"
            },
            "line_12": {
                "font_size": 10,
                "bold": false,
                "text": "the agent does not need explicit modeling of the environ-"
            },
            "line_13": {
                "font_size": 10,
                "bold": false,
                "text": "ment because its actions could be directly selected based on"
            },
            "line_14": {
                "font_size": 10,
                "bold": false,
                "text": "rewards. Q-learning is a model-independent approach where"
            },
            "line_15": {
                "font_size": 10,
                "bold": false,
                "text": "the agent does not access to transfer model [1,31]. Suppose"
            },
            "line_16": {
                "font_size": 10,
                "bold": false,
                "text": "that the agent is in a state s, performs an action a, from"
            },
            "line_17": {
                "font_size": 10,
                "bold": false,
                "text": "which it gets the rewards r from the environment and the"
            },
            "line_18": {
                "font_size": 10,
                "bold": false,
                "text": "environment changes to state s(cid:2). This is given by a tuple in"
            },
            "line_19": {
                "font_size": 10,
                "bold": false,
                "text": "the form of (s, a, r , s(cid:2)). State-action value which represents"
            },
            "line_20": {
                "font_size": 10,
                "bold": false,
                "text": "the expected total reward resulting from taking action a in"
            },
            "line_21": {
                "font_size": 10,
                "bold": false,
                "text": "state s is denoted by Q-value Q(s, a). The agent starts with"
            },
            "line_22": {
                "font_size": 10,
                "bold": false,
                "text": "random value and after each action they receive a tuple in the"
            },
            "line_23": {
                "font_size": 10,
                "bold": false,
                "text": "form of (s, a, r , s(cid:2)). For each tuple, the value of state-action"
            },
            "line_24": {
                "font_size": 10,
                "bold": false,
                "text": "could be calculated according to the following equation:"
            }
        },
        "paragraph_8": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "Q(s, a) = (1 − α)Q(s, a)"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "+ α"
            }
        },
        "paragraph_9": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "(cid:2)"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "r + γ max Q(s(cid:2), a(cid:2)) − Q(s, a)"
            }
        },
        "paragraph_10": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "(cid:3)"
            }
        },
        "paragraph_11": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "(1)"
            }
        },
        "paragraph_12": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "where α ∈ [0, 1] is the learning rate of agent. α = 1 means"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "that merely new information is considered and zero means"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "that the agent does not have any learning. γ ∈ [0, 1] is dis-"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "count factor which determines future rewards. Zero value"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "for this factor makes the agent opportunist which means that"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "the agent only considers current reward. On the other hand,"
            }
        },
        "paragraph_13": {},
        "paragraph_14": {}
    },
    "page_3": {
        "paragraph_0": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Arabian Journal for Science and Engineering"
            }
        },
        "paragraph_1": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "γ = 1 means that the agent will wait for a longer time to"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "achieve a large reward. Q-learning will converge to optimum"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "value Q∗(s, a) with probability of one if all state-action pairs"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "are experienced repetitively and learning rate decrease during"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "the time [22]. Generally, RL is useful for solving problems"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "with small dimension discrete state and action space. When"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "the dimension of state and action space becomes larger, the"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "size of search table will be so large that it makes the algorithm"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "very slow due to computational time. On the other hand, when"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "the states or actions are stated continuously, using search"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "table will not be possible. To tackle this problem, fuzzy the-"
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "ory is employed. If the intelligent agent has a proper fuzzy"
            },
            "line_12": {
                "font_size": 10,
                "bold": false,
                "text": "set as expert knowledge about the desired area, the ambigu-"
            },
            "line_13": {
                "font_size": 10,
                "bold": false,
                "text": "ity could be resolved. Thus, intelligent agent can understand"
            },
            "line_14": {
                "font_size": 10,
                "bold": false,
                "text": "vague objectives and unknown environment. In practice, the"
            },
            "line_15": {
                "font_size": 10,
                "bold": false,
                "text": "action in large spaces is facilitated by eliminating Q-values"
            },
            "line_16": {
                "font_size": 10,
                "bold": false,
                "text": "table. In this method everything is based on quality values"
            },
            "line_17": {
                "font_size": 10,
                "bold": false,
                "text": "and fuzzy inference. Fuzzy inference system (FIS) deals with"
            },
            "line_18": {
                "font_size": 10,
                "bold": false,
                "text": "input and Q-learning algorithm uses the follower section and"
            },
            "line_19": {
                "font_size": 10,
                "bold": false,
                "text": "its active rules as states. Reward signal of Q-algorithm is built"
            },
            "line_20": {
                "font_size": 10,
                "bold": false,
                "text": "in accordance with fuzzy logic, environment reward signal"
            },
            "line_21": {
                "font_size": 10,
                "bold": false,
                "text": "and performance estimation of current action. It is tried to"
            },
            "line_22": {
                "font_size": 10,
                "bold": false,
                "text": "select the action which maximizes the reward signal [9,14]."
            },
            "line_23": {
                "font_size": 10,
                "bold": false,
                "text": "Learning system is able to select one action among j actions"
            },
            "line_24": {
                "font_size": 10,
                "bold": false,
                "text": "for each rule. j-th possible action in i-th rule is denoted by"
            },
            "line_25": {
                "font_size": 10,
                "bold": false,
                "text": "a[i, j] and its value is shown by q[i, j] consider the follow-"
            },
            "line_26": {
                "font_size": 10,
                "bold": false,
                "text": "ing rules [9]:"
            }
        },
        "paragraph_2": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "If x is si"
            }
        },
        "paragraph_3": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "then a[i, 1] with q[i, 1]"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "a[i, 2] with q[i, 2]"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "or"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "..."
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "or"
            }
        },
        "paragraph_4": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "a[i, j] with q[i, j]"
            }
        },
        "paragraph_5": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "Learning should ﬁnd the best result for each rule. If the agent"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "selects an action which results in high value, it may learn"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "optimum policy. Thus, fuzzy inference system may obtain"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "necessary action for each rule [9]."
            }
        },
        "paragraph_6": {
            "line_0": {
                "font_size": 12,
                "bold": true,
                "text": "3 Game Theory in ITS"
            }
        },
        "paragraph_7": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "Relation between agent-oriented environments and games"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "theory originates from the fact that each state of agent-"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "oriented environments can be resembled to a game environ-"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "ment. Proﬁt function of players would be current state of the"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "environment and goal of players is to move toward balanced"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "or equilibrium point (reaching the best decision-making pol-"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "icy). Some scholars have studied the application of Game"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "theory to control of trafﬁc lights [15,16]. They integrate"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "Game theory into the multi-agent interaction approach. Some"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "of them suit the trafﬁc problem into a rigorous mathemati-"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "cal game model [5,8,11], while others modify the learning"
            }
        },
        "paragraph_8": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "method of agents based on Game theory [33]. In [5], signal-"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "ized intersections are modeled as ﬁnite controlled Markov"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "chains and each intersection is seen as non-cooperative game"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "where each player try to minimize its queue. The solutions"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "are given as Nash equilibrium and Stackelberbg equilibrium"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "and the simulation results indicate shorter queue length than"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "adaptive control. In [8], a two-player non-cooperative game"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "is articulated between user seeking a path to minimize the"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "expected trip cost and choosing link performance scenarios"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "to maximize the expected trip cost. It shows that the Nash"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "equilibrium point measures network performance. Intelli-"
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "gent trafﬁc control is expressed as a Cournot game where the"
            },
            "line_12": {
                "font_size": 10,
                "bold": false,
                "text": "trafﬁc authority and the users choose their strategies simulta-"
            },
            "line_13": {
                "font_size": 10,
                "bold": false,
                "text": "neously and as a bi-level Stackelberg game where the trafﬁc"
            },
            "line_14": {
                "font_size": 10,
                "bold": false,
                "text": "authority is the leader which determines the signal settings in"
            },
            "line_15": {
                "font_size": 10,
                "bold": false,
                "text": "anticipation of the user reactions. In [33], Game theory is used"
            },
            "line_16": {
                "font_size": 10,
                "bold": false,
                "text": "to address coordination between agents based on trafﬁc signal"
            },
            "line_17": {
                "font_size": 10,
                "bold": false,
                "text": "control with Q-learning. It speciﬁes strategies (C(m) ={red"
            },
            "line_18": {
                "font_size": 10,
                "bold": false,
                "text": "light time plus 4 s, red light time plus 8 s, red light time minus"
            },
            "line_19": {
                "font_size": 10,
                "bold": false,
                "text": "4 s, red light time minus 8 s,unchangeably}) and actions"
            },
            "line_20": {
                "font_size": 10,
                "bold": false,
                "text": "(S(n) ={east west straight and right turn, south north straight"
            },
            "line_21": {
                "font_size": 10,
                "bold": false,
                "text": "and right turn, east west left turn, south north left turn})."
            },
            "line_22": {
                "font_size": 10,
                "bold": false,
                "text": "Then, an interaction mathematical model via Game theory"
            },
            "line_23": {
                "font_size": 10,
                "bold": false,
                "text": "as a four parameter group G = {B, A, I , U } is presented."
            },
            "line_24": {
                "font_size": 10,
                "bold": false,
                "text": "B is a group of decision-makers as players. A is a group of"
            },
            "line_25": {
                "font_size": 10,
                "bold": false,
                "text": "any possible strategies and actions, i.e. A = C(m) ∗ S(n)."
            },
            "line_26": {
                "font_size": 10,
                "bold": false,
                "text": "I represents the information which agents masters. U is the"
            },
            "line_27": {
                "font_size": 10,
                "bold": false,
                "text": "beneﬁt function which adopts Q-value. So, the Nash equi-"
            },
            "line_28": {
                "font_size": 10,
                "bold": false,
                "text": "librium is [33]:"
            }
        },
        "paragraph_9": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Ui (a∗"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "i"
            }
        },
        "paragraph_10": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": ", a∗"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "−i"
            }
        },
        "paragraph_11": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": ") ≥ Ui (ai , a∗"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "−i"
            }
        },
        "paragraph_12": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": ")"
            }
        },
        "paragraph_13": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "(2)"
            }
        },
        "paragraph_14": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "(3)"
            }
        },
        "paragraph_15": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "where ai and a−i denote action of i-th agent and actions of"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "other agents, respectively. a∗"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "−i represent the actions"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "at Nash equilibrium. The renewed Q-values in distributed"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "reinforcement Q-learning are used to build the payoff values."
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "Q-value function is updated as:"
            }
        },
        "paragraph_16": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "i and a∗"
            }
        },
        "paragraph_17": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "Qi (si , ai ) = (1 − αi )Qi (si , ai )"
            }
        },
        "paragraph_18": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "⎡"
            }
        },
        "paragraph_19": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "+ αi"
            }
        },
        "paragraph_20": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "⎣ri (si , ai ) +"
            }
        },
        "paragraph_21": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "n(cid:6)"
            }
        },
        "paragraph_22": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "j=1, j(cid:6)=i"
            }
        },
        "paragraph_23": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "f (i, j)r j (si , ai )"
            }
        },
        "paragraph_24": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "⎤"
            }
        },
        "paragraph_25": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "⎦"
            }
        },
        "paragraph_26": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "(4)"
            }
        },
        "paragraph_27": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "+ γ max(Qi (s(cid:2)"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "i"
            }
        },
        "paragraph_28": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": ", a(cid:2)"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "i"
            }
        },
        "paragraph_29": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": ") − Qi (si , ai ))"
            }
        },
        "paragraph_30": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "where α and γ are learning rate and discount factor, respec-"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "tively. si and ai are current state of trafﬁc environment and"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "current action, respectively. s(cid:2)"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "i is its next state, n is the num-"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "ber of trafﬁc signal control agents surrounding i-th agent,"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "Qi (si , ai ) is the Q-value function for i-th agent when selects"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "action ai in state si . ri (si , ai ) is reward function of i-th agent"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "and r j (si , ai ) is reward function of j-th agent neighboring i-"
            }
        },
        "paragraph_31": {
            "line_0": {
                "font_size": 15,
                "bold": false,
                "text": "123"
            }
        },
        "paragraph_32": {},
        "paragraph_33": {}
    },
    "page_4": {
        "paragraph_0": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "th agent. f (i, j) ∈ [0, 1] is a weighted function which shows"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "the effect of r j (si , ai ) on i-th agent. Mathematical functions"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "are suggested in [33] for r (s, a) and f (i, j). Assumption of"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "discrete action-state space and determination of reward and"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "weighting functions are drawbacks of that work."
            }
        },
        "paragraph_1": {
            "line_0": {
                "font_size": 12,
                "bold": true,
                "text": "4 Problem Statements"
            }
        },
        "paragraph_2": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "Consider a trafﬁc network in which the lights of each inter-"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "section is controlled by an autonomous agents without any"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "centralized management. Some sensors which are installed"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "below the surface of surrounding streets or trafﬁc cameras"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "of each intersection provide information about trafﬁc situa-"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "tion for the corresponding agent. An agent has to decide on"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "duration of green light at north–south (NS) and west–east"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "(WE) paths. Also, any agent interacts with neighbor agents."
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "Anyway, the agent is expected to schedule trafﬁc lights opti-"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "mally, in the sense of average delay, based on the received"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "information from its sensors and received information from"
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "neighbor agents."
            }
        },
        "paragraph_3": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "The agents may have little knowledge about others’ deci-"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "sion due to distribution of information. Even if an agent has"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "previous known information about others’ decision, it is not"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "valid as other agents are also learning. Thus, the environ-"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "ment is dynamic and the behavior of other agents may change"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "during time. Lack of prediction of other agents causes uncer-"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "tainty in problem solving procedure. This paper looks for a"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "decision-making algorithm for lights control agents which"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "considers neighbor agents information in addition to its own"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "information."
            }
        },
        "paragraph_4": {
            "line_0": {
                "font_size": 12,
                "bold": true,
                "text": "5 Proposed Algorithm"
            }
        },
        "paragraph_5": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "We consider a constant duration T for green plus red phases."
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "So, if the agent determines the green phase duration tg, then"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "the red phase duration is tr = T − tg. Any typical agent i"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "receives number of vehicles on the NS and WE streets from"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "its own sensors and the green phase duration of neighbor"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "agent j in order to schedule its own green phase duration."
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "This paper proposes an autonomous agent with structure in"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "Fig. 1 to control each intersection."
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "The number of vehicles in WE and NS streets which are mea-"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "sured by sensors are fuzziﬁed. Then, a fuzzy inference engine"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "with rules as Eq. 2 are employed to ﬁre the corresponding"
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "output membership functions. Finally, defuzziﬁcation results"
            },
            "line_12": {
                "font_size": 8,
                "bold": false,
                "text": "to duration of green phase in NS path (t N S"
            },
            "line_13": {
                "font_size": 10,
                "bold": false,
                "text": "). Thus, the dura-"
            },
            "line_14": {
                "font_size": 8,
                "bold": false,
                "text": "= T −t N S"
            },
            "line_15": {
                "font_size": 8,
                "bold": false,
                "text": "tion of green phase in other path, WE, is t W E"
            },
            "line_16": {
                "font_size": 10,
                "bold": false,
                "text": ". We"
            },
            "line_17": {
                "font_size": 10,
                "bold": false,
                "text": "propose that, Q-value function which is updated by Eq. 4 be"
            },
            "line_18": {
                "font_size": 10,
                "bold": false,
                "text": "the value of each action in Eq. 2 which is denoted by q[i, j]."
            },
            "line_19": {
                "font_size": 10,
                "bold": false,
                "text": "This update equation takes the neighbor agents’ decision into"
            },
            "line_20": {
                "font_size": 10,
                "bold": false,
                "text": "account."
            }
        },
        "paragraph_6": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "g"
            }
        },
        "paragraph_7": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "g"
            }
        },
        "paragraph_8": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "g"
            }
        },
        "paragraph_9": {
            "line_0": {
                "font_size": 15,
                "bold": false,
                "text": "123"
            }
        },
        "paragraph_10": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Arabian Journal for Science and Engineering"
            }
        },
        "paragraph_11": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Fig. 1 The proposed structure for a typical agent"
            }
        },
        "paragraph_12": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "The i-th agent takes decision of neighbor agent"
            }
        },
        "paragraph_13": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "j into"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "account by reward r j (si , ai ) and a weighting function"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "f (i, j). The reward is calculated based on average delay"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "obtained from the decision made by the agent and current"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "trafﬁc situation in a fuzzy manner. A fuzzy inference engine"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "obtains these two inputs after fuzziﬁcation and gives the"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "reward after defuzziﬁcation; see Fig. 1. weighting function"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "f (i, j) ∈ [0, 1] shows the effect of r j (si , ai ) on the deci-"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "sion of i-th agent. This weight is also calculated by a fuzzy"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "inference engine. This engine takes its own tg, the neighbor"
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "agents’ tg, and number of waited vehicles and gives f (i, j)."
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "Suitable choice for reward and weighting function plays a"
            },
            "line_12": {
                "font_size": 10,
                "bold": false,
                "text": "signiﬁcant role in agent learning. The agent with structure in"
            },
            "line_13": {
                "font_size": 10,
                "bold": false,
                "text": "Fig. 1 runs the following algorithm:"
            }
        },
        "paragraph_14": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "1. Initial value of Qi -value for i-th trafﬁc signal control"
            }
        },
        "paragraph_15": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "agent is in the form of ∀(si , ai ) : Qi (si , ai ) = 0."
            }
        },
        "paragraph_16": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "2. Observing si by WE and NS sensors which is the current"
            }
        },
        "paragraph_17": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "state of i-th intersection."
            }
        },
        "paragraph_18": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "3. Selecting a proper estimation for desired state by fuzzy"
            }
        },
        "paragraph_19": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "inference system."
            }
        },
        "paragraph_20": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "4. Calculating the reward related to i-th and j-th trafﬁc"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "signal control agent and the weighting function for neigh-"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "boring agents separately."
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "5. Observing new state s(cid:2)"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "i ."
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "6. Updating Qi -value according to Eq. 4."
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "7. Returning to step 2 till the variation of Q-value becomes"
            }
        },
        "paragraph_21": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "less than (cid:4)."
            }
        },
        "paragraph_22": {
            "line_0": {
                "font_size": 12,
                "bold": true,
                "text": "6 Simulation Results"
            }
        },
        "paragraph_23": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "Consider a trafﬁc network with a center and four neighbor"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "intersection. The delay in each intersection depends on phys-"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "ical characteristics of the intersection, trafﬁc light scheduling"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "and number of cars in input streets. We utilized trafﬁc model"
            }
        },
        "paragraph_24": {},
        "paragraph_25": {},
        "paragraph_26": {},
        "paragraph_27": {}
    },
    "page_5": {
        "paragraph_0": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Arabian Journal for Science and Engineering"
            }
        },
        "paragraph_1": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1"
            }
        },
        "paragraph_2": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.8"
            }
        },
        "paragraph_3": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.6"
            }
        },
        "paragraph_4": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.4"
            }
        },
        "paragraph_5": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.2"
            }
        },
        "paragraph_6": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_7": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_8": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "VL"
            }
        },
        "paragraph_9": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "L"
            }
        },
        "paragraph_10": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "M"
            }
        },
        "paragraph_11": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "H"
            }
        },
        "paragraph_12": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "VH"
            }
        },
        "paragraph_13": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "500"
            }
        },
        "paragraph_14": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1000 1500 2000 2500 3000 3500"
            }
        },
        "paragraph_15": {
            "line_0": {
                "font_size": 9,
                "bold": false,
                "text": "Number of vehivles"
            }
        },
        "paragraph_16": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1"
            }
        },
        "paragraph_17": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.8"
            }
        },
        "paragraph_18": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.6"
            }
        },
        "paragraph_19": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.4"
            }
        },
        "paragraph_20": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.2"
            }
        },
        "paragraph_21": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_22": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_23": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "VS"
            }
        },
        "paragraph_24": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "S"
            }
        },
        "paragraph_25": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "M"
            }
        },
        "paragraph_26": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "H"
            }
        },
        "paragraph_27": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "VH"
            }
        },
        "paragraph_28": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "10"
            }
        },
        "paragraph_29": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "20"
            }
        },
        "paragraph_30": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "30"
            },
            "line_1": {
                "font_size": 9,
                "bold": false,
                "text": "Delay"
            }
        },
        "paragraph_31": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "40"
            }
        },
        "paragraph_32": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "50"
            }
        },
        "paragraph_33": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "60"
            }
        },
        "paragraph_34": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Fig. 2 Membership function of number of vehicles enter the street for"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "reward FIS"
            }
        },
        "paragraph_35": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Fig. 3 Membership function of average delay for reward FIS"
            }
        },
        "paragraph_36": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "which is given by the American Highway Capacity Manual"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "(HCM) [4, Eq.20]:"
            }
        },
        "paragraph_37": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "d = 0.38"
            }
        },
        "paragraph_38": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "C(1 − λ)2"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "1 − x"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "(cid:9)"
            }
        },
        "paragraph_39": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "+ 173x 2"
            }
        },
        "paragraph_40": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "(x − 1) +"
            }
        },
        "paragraph_41": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "(cid:11)"
            }
        },
        "paragraph_42": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "(cid:10)"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "(x − 1)2 + 16x"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "C"
            }
        },
        "paragraph_43": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "(5)"
            }
        },
        "paragraph_44": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "where d, C, λ, and x are average delay (s), cycle time (s),"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "green ratio, and degree of saturation, respectively. λ = g"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "c"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "and x = v"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "c , where c, g, and v are capacity (vehicle per hour),"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "green time (sec), and input volume, respectively. We use this"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "model to calculate average delay based on the green phase"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "duration and number of vehicles. For more details of this"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "equation, we refer to [4]."
            }
        },
        "paragraph_45": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "Assume that C = T = 100 s and c = 3500 veh/h. v is"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "volume of vehicles entering each street which varies between"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "0 to 3500 veh/h. g is duration of the green phase which each"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "agent selects considering fuzzy Q-learning and interaction"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "with adjacent agents. The trafﬁc network simulation algo-"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "rithm is as follow:"
            }
        },
        "paragraph_46": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "1. The volume of vehicles entering each intersection (v) are"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "randomly generated by a discrete uniform distribution on"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "the interval [0, 3500]."
            }
        },
        "paragraph_47": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "2. Average delay is calculated by Eq. 5."
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "3. Each agent decides on the time of green phase g."
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "4. Go to step 1 until end of simulation time."
            }
        },
        "paragraph_48": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "Assume structure of the agents as in Fig. 1 with the Mam-"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "dani FIS with input membership function as in Fig. 2 for"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "number of input vehicles and Fig. 3 for average delay to"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "calculate the reward functions r j (si , ai ). Centroid defuzzi-"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "ﬁcation by the output membership function as in Fig. 4 is"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "considered to estimate a reward value in interval [− 3, 3]."
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "The weighting function FIS has number of vehicles, its own"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "green phase duration and the neighbor agents’ green phase"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "duration as inputs. Figure 2 shows the membership function"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "for number of vehicles, and Fig. 5 depicts the membership"
            }
        },
        "paragraph_49": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "VS"
            }
        },
        "paragraph_50": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1"
            }
        },
        "paragraph_51": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.8"
            }
        },
        "paragraph_52": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.6"
            }
        },
        "paragraph_53": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.4"
            }
        },
        "paragraph_54": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.2"
            }
        },
        "paragraph_55": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_56": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "-3"
            }
        },
        "paragraph_57": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "S"
            }
        },
        "paragraph_58": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "M"
            }
        },
        "paragraph_59": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "H"
            }
        },
        "paragraph_60": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "VH"
            }
        },
        "paragraph_61": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "-2"
            }
        },
        "paragraph_62": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "-1"
            }
        },
        "paragraph_63": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            },
            "line_1": {
                "font_size": 9,
                "bold": false,
                "text": "Reward"
            }
        },
        "paragraph_64": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1"
            }
        },
        "paragraph_65": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "2"
            }
        },
        "paragraph_66": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "3"
            }
        },
        "paragraph_67": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Fig. 4 Membership function of output for reward FIS"
            }
        },
        "paragraph_68": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1"
            }
        },
        "paragraph_69": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.8"
            }
        },
        "paragraph_70": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.6"
            }
        },
        "paragraph_71": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.4"
            }
        },
        "paragraph_72": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.2"
            }
        },
        "paragraph_73": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_74": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_75": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "L"
            }
        },
        "paragraph_76": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "M"
            }
        },
        "paragraph_77": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "H"
            }
        },
        "paragraph_78": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "20"
            }
        },
        "paragraph_79": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "40"
            }
        },
        "paragraph_80": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "60"
            }
        },
        "paragraph_81": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "80"
            }
        },
        "paragraph_82": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "100"
            }
        },
        "paragraph_83": {
            "line_0": {
                "font_size": 9,
                "bold": false,
                "text": "Green phase duration"
            }
        },
        "paragraph_84": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Fig. 5 Membership function of green phase duration for weighting"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "function FIS"
            }
        },
        "paragraph_85": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "function for its own and neighbor green phase duration. Cen-"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "troid defuzziﬁcation is applied to calculate weights on output"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "membership function as in Fig. 6 which should be a value"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "between 0 and 1."
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "Finally, the agent uses fuzzy Q-learning (Eq. 2) with Q-value"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "update rule (Eq. 4) where learning and discount factor are"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "selected to be 0.5 and 0.7, respectively. The membership"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "function for each measured number of vehicles is shown in"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "Fig. 7. The output estimates green phase duration with mem-"
            },
            "line_9": {
                "font_size": 10,
                "bold": false,
                "text": "bership functions as in Fig. 8."
            },
            "line_10": {
                "font_size": 10,
                "bold": false,
                "text": "The proposed method is compared with Fuzzy Q-learning"
            },
            "line_11": {
                "font_size": 10,
                "bold": false,
                "text": "(using Eq. 2 where q[i, j] is the Q-value which updates"
            },
            "line_12": {
                "font_size": 10,
                "bold": false,
                "text": "with Eq. 1), Q-learning (using Q-learning method with Q-"
            },
            "line_13": {
                "font_size": 10,
                "bold": false,
                "text": "value which updates with Eq. 1), fuzzy(using traditional"
            },
            "line_14": {
                "font_size": 10,
                "bold": false,
                "text": "fuzzy inference method) and ﬁxed time (tg = 60 s) in"
            },
            "line_15": {
                "font_size": 10,
                "bold": false,
                "text": "the sense of total average delay. Average delay in each"
            }
        },
        "paragraph_86": {
            "line_0": {
                "font_size": 15,
                "bold": false,
                "text": "123"
            }
        },
        "paragraph_87": {},
        "paragraph_88": {},
        "paragraph_89": {},
        "paragraph_90": {},
        "paragraph_91": {},
        "paragraph_92": {},
        "paragraph_93": {},
        "paragraph_94": {},
        "paragraph_95": {},
        "paragraph_96": {},
        "paragraph_97": {},
        "paragraph_98": {},
        "paragraph_99": {},
        "paragraph_100": {},
        "paragraph_101": {},
        "paragraph_102": {},
        "paragraph_103": {},
        "paragraph_104": {},
        "paragraph_105": {},
        "paragraph_106": {},
        "paragraph_107": {},
        "paragraph_108": {},
        "paragraph_109": {},
        "paragraph_110": {},
        "paragraph_111": {},
        "paragraph_112": {},
        "paragraph_113": {},
        "paragraph_114": {},
        "paragraph_115": {},
        "paragraph_116": {},
        "paragraph_117": {},
        "paragraph_118": {},
        "paragraph_119": {},
        "paragraph_120": {},
        "paragraph_121": {},
        "paragraph_122": {},
        "paragraph_123": {},
        "paragraph_124": {},
        "paragraph_125": {},
        "paragraph_126": {},
        "paragraph_127": {},
        "paragraph_128": {},
        "paragraph_129": {},
        "paragraph_130": {},
        "paragraph_131": {},
        "paragraph_132": {},
        "paragraph_133": {},
        "paragraph_134": {},
        "paragraph_135": {},
        "paragraph_136": {},
        "paragraph_137": {},
        "paragraph_138": {},
        "paragraph_139": {},
        "paragraph_140": {},
        "paragraph_141": {},
        "paragraph_142": {},
        "paragraph_143": {},
        "paragraph_144": {},
        "paragraph_145": {},
        "paragraph_146": {},
        "paragraph_147": {},
        "paragraph_148": {},
        "paragraph_149": {},
        "paragraph_150": {},
        "paragraph_151": {},
        "paragraph_152": {},
        "paragraph_153": {},
        "paragraph_154": {},
        "paragraph_155": {},
        "paragraph_156": {},
        "paragraph_157": {},
        "paragraph_158": {},
        "paragraph_159": {},
        "paragraph_160": {},
        "paragraph_161": {},
        "paragraph_162": {},
        "paragraph_163": {},
        "paragraph_164": {},
        "paragraph_165": {},
        "paragraph_166": {},
        "paragraph_167": {},
        "paragraph_168": {},
        "paragraph_169": {},
        "paragraph_170": {},
        "paragraph_171": {},
        "paragraph_172": {},
        "paragraph_173": {},
        "paragraph_174": {},
        "paragraph_175": {},
        "paragraph_176": {},
        "paragraph_177": {},
        "paragraph_178": {},
        "paragraph_179": {}
    },
    "page_6": {
        "paragraph_0": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "VS"
            }
        },
        "paragraph_1": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "S"
            }
        },
        "paragraph_2": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "M"
            }
        },
        "paragraph_3": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "H"
            }
        },
        "paragraph_4": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "VH"
            }
        },
        "paragraph_5": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Arabian Journal for Science and Engineering"
            }
        },
        "paragraph_6": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.2"
            }
        },
        "paragraph_7": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.4"
            }
        },
        "paragraph_8": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.6"
            }
        },
        "paragraph_9": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.8"
            }
        },
        "paragraph_10": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1"
            }
        },
        "paragraph_11": {
            "line_0": {
                "font_size": 9,
                "bold": false,
                "text": "Weight"
            }
        },
        "paragraph_12": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1"
            }
        },
        "paragraph_13": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.8"
            }
        },
        "paragraph_14": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.6"
            }
        },
        "paragraph_15": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.4"
            }
        },
        "paragraph_16": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.2"
            }
        },
        "paragraph_17": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_18": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_19": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Fig. 6 Membership function of output for weighting function FIS"
            }
        },
        "paragraph_20": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1"
            }
        },
        "paragraph_21": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.8"
            }
        },
        "paragraph_22": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.6"
            }
        },
        "paragraph_23": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.4"
            }
        },
        "paragraph_24": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.2"
            }
        },
        "paragraph_25": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_26": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_27": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "VL"
            }
        },
        "paragraph_28": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "L"
            }
        },
        "paragraph_29": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "H"
            }
        },
        "paragraph_30": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "VH"
            }
        },
        "paragraph_31": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "500"
            }
        },
        "paragraph_32": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1000 1500 2000 2500 3000 3500"
            }
        },
        "paragraph_33": {
            "line_0": {
                "font_size": 9,
                "bold": false,
                "text": "Number of vehivles"
            }
        },
        "paragraph_34": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Fig. 9 Delay of the proposed method, ﬁxed time, fuzzy Q-learning,"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "Q-learning and fuzzy in each time step"
            }
        },
        "paragraph_35": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Fig. 7 Membership function of number of vehicles for fuzzy Q-learning"
            }
        },
        "paragraph_36": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1"
            }
        },
        "paragraph_37": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.8"
            }
        },
        "paragraph_38": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.6"
            }
        },
        "paragraph_39": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.4"
            }
        },
        "paragraph_40": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0.2"
            }
        },
        "paragraph_41": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_42": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "0"
            }
        },
        "paragraph_43": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "S1"
            }
        },
        "paragraph_44": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "S2 S3 S4 S5 S6 S7 S8 S9"
            }
        },
        "paragraph_45": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "20"
            }
        },
        "paragraph_46": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "40"
            }
        },
        "paragraph_47": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "60"
            }
        },
        "paragraph_48": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "80"
            }
        },
        "paragraph_49": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "100"
            }
        },
        "paragraph_50": {
            "line_0": {
                "font_size": 9,
                "bold": false,
                "text": "green phase duration"
            }
        },
        "paragraph_51": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Fig. 10 Average of delay for the proposed method, ﬁxed time, fuzzy,"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "Q-learning, fuzzy Q-learning"
            }
        },
        "paragraph_52": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Fig. 8 Membership function of green phase duration for fuzzy Q-"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "learning"
            }
        },
        "paragraph_53": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "time interval is depicted in Fig. 9, and the total average"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "delay is illustrated in Fig. 10. The results illustrate that"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "total average delay decrease from more than 50 s for ﬁxed"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "time scheduling to approximately 15 s for the proposed"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "method."
            }
        },
        "paragraph_54": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "The reward received from the neighbor and weighted func-"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "tions of neighboring agents are factors learning algorithm."
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "These parameters are fuzziﬁed through a FIS. Also, the"
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "number of vehicles in each street is measured and fuzzi-"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "ﬁed to be used in decision-making process. The simulation"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "results were compared with ﬁxed time method and other"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "intelligent methods. The results revealed that our proposed"
            },
            "line_7": {
                "font_size": 10,
                "bold": false,
                "text": "method achieves considerable reduction of average delay in"
            },
            "line_8": {
                "font_size": 10,
                "bold": false,
                "text": "intersections."
            }
        },
        "paragraph_55": {
            "line_0": {
                "font_size": 12,
                "bold": true,
                "text": "7 Conclusion"
            }
        },
        "paragraph_56": {
            "line_0": {
                "font_size": 10,
                "bold": false,
                "text": "In this study, an intelligent control method of a controlling"
            },
            "line_1": {
                "font_size": 10,
                "bold": false,
                "text": "trafﬁc network was performed to decrease average delay"
            },
            "line_2": {
                "font_size": 10,
                "bold": false,
                "text": "time. Each trafﬁc light is considered as a learning agent."
            },
            "line_3": {
                "font_size": 10,
                "bold": false,
                "text": "This paper proposed a structure for the agents. Each agent"
            },
            "line_4": {
                "font_size": 10,
                "bold": false,
                "text": "learn to decide on the duration of green phase through a"
            },
            "line_5": {
                "font_size": 10,
                "bold": false,
                "text": "fuzzy Q-learning algorithm which is modiﬁed by Game the-"
            },
            "line_6": {
                "font_size": 10,
                "bold": false,
                "text": "ory. Each agent receives a reward from neighbor agents."
            }
        },
        "paragraph_57": {
            "line_0": {
                "font_size": 12,
                "bold": true,
                "text": "References"
            }
        },
        "paragraph_58": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "1. Abdoos, M.; Mozayani, N.; Bazzan, A.L.: Trafﬁc light control in"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "non-stationary environments based on multi agent q-learning. In:"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "14th International IEEE Conference on Intelligent Transportation"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "Systems (ITSC), pp. 1580–1585. IEEE (2011)"
            }
        },
        "paragraph_59": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "2. Abdulhai, B.; Pringle, R.; Karakoulas, G.J.: Reinforcement learn-"
            },
            "line_1": {
                "font_size": 8,
                "bold": true,
                "text": "ing for true adaptive trafﬁc signal control. J. Transp. Eng. 129(3),"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "278–285 (2003)"
            }
        },
        "paragraph_60": {
            "line_0": {
                "font_size": 15,
                "bold": false,
                "text": "123"
            }
        },
        "paragraph_61": {},
        "paragraph_62": {},
        "paragraph_63": {},
        "paragraph_64": {},
        "paragraph_65": {},
        "paragraph_66": {},
        "paragraph_67": {},
        "paragraph_68": {},
        "paragraph_69": {},
        "paragraph_70": {},
        "paragraph_71": {},
        "paragraph_72": {},
        "paragraph_73": {},
        "paragraph_74": {},
        "paragraph_75": {},
        "paragraph_76": {},
        "paragraph_77": {},
        "paragraph_78": {},
        "paragraph_79": {},
        "paragraph_80": {},
        "paragraph_81": {},
        "paragraph_82": {},
        "paragraph_83": {},
        "paragraph_84": {},
        "paragraph_85": {},
        "paragraph_86": {},
        "paragraph_87": {},
        "paragraph_88": {},
        "paragraph_89": {},
        "paragraph_90": {},
        "paragraph_91": {},
        "paragraph_92": {},
        "paragraph_93": {},
        "paragraph_94": {},
        "paragraph_95": {},
        "paragraph_96": {},
        "paragraph_97": {},
        "paragraph_98": {},
        "paragraph_99": {},
        "paragraph_100": {},
        "paragraph_101": {},
        "paragraph_102": {},
        "paragraph_103": {},
        "paragraph_104": {},
        "paragraph_105": {},
        "paragraph_106": {},
        "paragraph_107": {},
        "paragraph_108": {},
        "paragraph_109": {},
        "paragraph_110": {},
        "paragraph_111": {},
        "paragraph_112": {},
        "paragraph_113": {},
        "paragraph_114": {},
        "paragraph_115": {},
        "paragraph_116": {},
        "paragraph_117": {},
        "paragraph_118": {},
        "paragraph_119": {},
        "paragraph_120": {},
        "paragraph_121": {},
        "paragraph_122": {},
        "paragraph_123": {},
        "paragraph_124": {},
        "paragraph_125": {},
        "paragraph_126": {},
        "paragraph_127": {},
        "paragraph_128": {},
        "paragraph_129": {},
        "paragraph_130": {},
        "paragraph_131": {},
        "paragraph_132": {},
        "paragraph_133": {},
        "paragraph_134": {},
        "paragraph_135": {},
        "paragraph_136": {},
        "paragraph_137": {},
        "paragraph_138": {},
        "paragraph_139": {},
        "paragraph_140": {},
        "paragraph_141": {},
        "paragraph_142": {},
        "paragraph_143": {},
        "paragraph_144": {},
        "paragraph_145": {},
        "paragraph_146": {},
        "paragraph_147": {},
        "paragraph_148": {},
        "paragraph_149": {},
        "paragraph_150": {},
        "paragraph_151": {},
        "paragraph_152": {},
        "paragraph_153": {},
        "paragraph_154": {},
        "paragraph_155": {},
        "paragraph_156": {},
        "paragraph_157": {},
        "paragraph_158": {},
        "paragraph_159": {},
        "paragraph_160": {},
        "paragraph_161": {},
        "paragraph_162": {},
        "paragraph_163": {},
        "paragraph_164": {},
        "paragraph_165": {},
        "paragraph_166": {},
        "paragraph_167": {},
        "paragraph_168": {},
        "paragraph_169": {},
        "paragraph_170": {},
        "paragraph_171": {},
        "paragraph_172": {},
        "paragraph_173": {},
        "paragraph_174": {},
        "paragraph_175": {},
        "paragraph_176": {},
        "paragraph_177": {},
        "paragraph_178": {},
        "paragraph_179": {},
        "paragraph_180": {},
        "paragraph_181": {},
        "paragraph_182": {},
        "paragraph_183": {},
        "paragraph_184": {},
        "paragraph_185": {},
        "paragraph_186": {},
        "paragraph_187": {},
        "paragraph_188": {},
        "paragraph_189": {},
        "paragraph_190": {},
        "paragraph_191": {},
        "paragraph_192": {},
        "paragraph_193": {},
        "paragraph_194": {},
        "paragraph_195": {},
        "paragraph_196": {},
        "paragraph_197": {},
        "paragraph_198": {},
        "paragraph_199": {},
        "paragraph_200": {},
        "paragraph_201": {}
    },
    "page_7": {
        "paragraph_0": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Arabian Journal for Science and Engineering"
            }
        },
        "paragraph_1": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "3. Adler, J.L.; Satapathy, G.; Manikonda, V.; Bowles, B.; Blue, V.J.: A"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "multi-agent approach to cooperative trafﬁc management and route"
            },
            "line_2": {
                "font_size": 8,
                "bold": true,
                "text": "guidance. Transp. Res. Part B Methodol. 39(4), 297–318 (2005)"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "4. Akgungor, A.P.; Bullen, A.G.R.: Analytical delay models for sig-"
            },
            "line_4": {
                "font_size": 8,
                "bold": false,
                "text": "nalized intersections. In: 69th ITE Annual Meeting, Nevada, USA"
            },
            "line_5": {
                "font_size": 8,
                "bold": false,
                "text": "(1999)"
            }
        },
        "paragraph_2": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "5. Alvarez, I.; Poznyak, A.; Malo, A.: Urban trafﬁc control problem a"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "game theory approach. In: 47th IEEE Conference on Decision and"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "Control, pp. 2168–2172. IEEE (2008)"
            }
        },
        "paragraph_3": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "6. Balaji, P.; German, X.; Srinivasan, D.: Urban trafﬁc signal control"
            },
            "line_1": {
                "font_size": 8,
                "bold": true,
                "text": "using reinforcement learning agents. IET Intell. Transp. Syst. 4(3),"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "177–188 (2010)"
            }
        },
        "paragraph_4": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "7. Bazzan, A.L.; Klgl, F.: A review on agent-based technology for traf-"
            },
            "line_1": {
                "font_size": 8,
                "bold": true,
                "text": "ﬁc and transportation. Knowl. Eng. Rev. 29(03), 375–403 (2014)"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "8. Bell, M.G.: A game theory approach to measuring the performance"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "reliability of transport networks. Transp. Res. Part B Methodol."
            },
            "line_4": {
                "font_size": 8,
                "bold": true,
                "text": "34(6), 533–545 (2000)"
            }
        },
        "paragraph_5": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "9. Bonarini, A.; Lazaric, A.; Montrone, F.; Restelli, M.: Reinforce-"
            },
            "line_1": {
                "font_size": 8,
                "bold": true,
                "text": "ment distribution in fuzzy q-learning. Fuzzy Sets Syst. 160(10),"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "1420–1443 (2009)"
            }
        },
        "paragraph_6": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "10. Bull, L.; ShaAban, J.; Tomlinson, A.; Addison, J.D.; Heydecker,"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "B.G.: Towards distributed adaptive control for road trafﬁc junction"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "signals using learning classiﬁer systems. In: Bull, L. (ed.) Applica-"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "tions of Learning Classiﬁer Systems, pp. 276–299. Springer, Berlin"
            },
            "line_4": {
                "font_size": 8,
                "bold": false,
                "text": "(2004)"
            }
        },
        "paragraph_7": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "11. Chen, O.; Ben-Akiva, M.: Game-theoretic formulations of interac-"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "tion between dynamic trafﬁc control and dynamic trafﬁc assign-"
            },
            "line_2": {
                "font_size": 8,
                "bold": true,
                "text": "ment. Transp. Res. Rec. J. Transp. Res. Board 1617, 179–188"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "(1998)"
            }
        },
        "paragraph_8": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "12. Chin, Y.K.; Bolong, N.; Kiring, A.; Yang, S.S.; Teo, K.T.K.: Q-"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "learning based trafﬁc optimization in management of signal timing"
            },
            "line_2": {
                "font_size": 8,
                "bold": true,
                "text": "plan. Int. J. Simul. Syst. Sci. Technol. 12(3), 29–35 (2011)"
            }
        },
        "paragraph_9": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "13. Da Silva, B.C.; Basso, E.W.; Perotto, F.S.; C Bazzan, A.L.; Engel,"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "P.M.: Improving reinforcement learning with context detection."
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "In: Proceedings of the Fifth International Joint Conference on"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "Autonomous Agents and Multiagent Systems, pp. 810–812. ACM"
            },
            "line_4": {
                "font_size": 8,
                "bold": false,
                "text": "(2006)"
            }
        },
        "paragraph_10": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "14. Glowaty, G.: Enhancements of fuzzy q-learning algorithm. Com-"
            }
        },
        "paragraph_11": {
            "line_0": {
                "font_size": 8,
                "bold": true,
                "text": "put. Sci. 7, 77–87 (2005)"
            }
        },
        "paragraph_12": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "15. Goyal, T.; Kaushal, S.: An intelligent scheduling scheme for real-"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "time trafﬁc management using cooperative game theory and ahp-"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "topsis methods for next generation telecommunication networks."
            },
            "line_3": {
                "font_size": 8,
                "bold": true,
                "text": "Expert Syst. Appl. 86, 125–134 (2017)"
            }
        },
        "paragraph_13": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "16. Groot, N.; Zaccour, G.; De Schutter, B.: Hierarchical game the-"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "ory for system-optimal control: applications of reverse stackelberg"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "games in regulating marketing channels and trafﬁc routing. IEEE"
            },
            "line_3": {
                "font_size": 8,
                "bold": true,
                "text": "Control Syst. 37(2), 129–152 (2017)"
            }
        },
        "paragraph_14": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "17. Houli, D.; Zhiheng, L.; Yi, Z.: Multiobjective reinforcement learn-"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "ing for trafﬁc signal control using vehicular ad hoc network."
            },
            "line_2": {
                "font_size": 8,
                "bold": true,
                "text": "EURASIP J. Adv. Signal Process. 1, 724,035 (2010)"
            }
        },
        "paragraph_15": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "18. Iyer, V.; Jadhav, R.; Mavchi, U.; Abraham, J.: Intelligent trafﬁc"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "signal synchronization using fuzzy logic and q-learning. In: Inter-"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "national Conference on Computing, Analytics and Security Trends"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "(CAST), pp. 156–161. IEEE (2016)"
            }
        },
        "paragraph_16": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "19. Kponyo, J.; Nwizege, K.; Opare, K.; Ahmed, A.; Hamdoun, H.;"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "Akazua, L.; Alshehri, S.; Frank, H.: A distributed intelligent traf-"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "ﬁc system using ant colony optimization: a netlogo modeling"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "approach. In: International Conference on Systems Informatics,"
            },
            "line_4": {
                "font_size": 8,
                "bold": false,
                "text": "Modelling and Simulation (SIMS), pp. 11–17. IEEE (2016)"
            },
            "line_5": {
                "font_size": 8,
                "bold": false,
                "text": "20. Liu, Z.: A survey of intelligence methods in urban trafﬁc signal"
            },
            "line_6": {
                "font_size": 8,
                "bold": true,
                "text": "control. IJCSNS Int. J. Comput. Sci. Netw. Secur. 7(7), 105–112"
            },
            "line_7": {
                "font_size": 8,
                "bold": false,
                "text": "(2007)"
            }
        },
        "paragraph_17": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "21. Medina, J.C.; Hajbabaie, A.; Benekohal, R.F.: Arterial trafﬁc con-"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "trol using reinforcement learning agents and information from"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "adjacent intersections in the state and reward structure. In: 2010"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "13th International IEEE Conference on Intelligent Transportation"
            },
            "line_4": {
                "font_size": 8,
                "bold": false,
                "text": "Systems (ITSC), pp. 525–530. IEEE (2010)"
            }
        },
        "paragraph_18": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "22. Pacheco, J.C.; Rossetti, R.J.: Agent-based trafﬁc control: a fuzzy"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "q-learning approach. In: 13th International IEEE Conference on"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "Intelligent Transportation Systems (ITSC), pp. 1172–1177. IEEE"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "(2010)"
            }
        },
        "paragraph_19": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "23. Prashanth, L.; Bhatnagar, S.: Reinforcement learning with function"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "approximation for trafﬁc signal control. IEEE Trans. Intell. Transp."
            },
            "line_2": {
                "font_size": 8,
                "bold": true,
                "text": "Syst. 12(2), 412–421 (2011)"
            }
        },
        "paragraph_20": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "24. Rida, M.: Modeling and optimization of decision-making process"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "during loading and unloading operations at container port. Arab. J."
            },
            "line_2": {
                "font_size": 8,
                "bold": true,
                "text": "Sci. Eng. 39(11), 8395–8408 (2014)"
            }
        },
        "paragraph_21": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "25. Roess, R.P.; Prassas, E.S.; McShane, W.R.: Trafﬁc Engineering."
            }
        },
        "paragraph_22": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "Prentice Hall, Englewood Cliffs (2004)"
            }
        },
        "paragraph_23": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "26. Salkham, A.; Cunningham, R.; Garg, A.; Cahill, V.: A collaborative"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "reinforcement learning approach to urban trafﬁc control optimiza-"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "tion. In: Proceedings of IEEE/WIC/ACM International Conference"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "on Web Intelligence and Intelligent Agent Technology, pp. 560–"
            },
            "line_4": {
                "font_size": 8,
                "bold": false,
                "text": "566. IEEE Computer Society (2008)"
            }
        },
        "paragraph_24": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "27. Schaefer, M.; Vokˇrínek, J.; Pinotti, D.; Tango, F.: Multi-agent trafﬁc"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "simulation for development and validation of autonomic car-to-car"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "systems. In: McCluskey, Th.L., Kotsialos, A., Müller, J.P., Klügl, F.,"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "Rana, O., Schumann, R. (eds.) Autonomic Road Transport Support"
            },
            "line_4": {
                "font_size": 8,
                "bold": false,
                "text": "Systems, pp. 165–180. Springer, Berlin (2016)"
            }
        },
        "paragraph_25": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "28. Steingrover, M.; Schouten, R.; Peelen, S.; Nijhuis, E.; Bakker, B.:"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "Reinforcement learning of trafﬁc light controllers adapting to trafﬁc"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "congestion. In: BNAIC, pp. 216–223. Citeseer (2005)"
            }
        },
        "paragraph_26": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "29. Teknomo, K.: Application of microscopic pedestrian simulation"
            },
            "line_1": {
                "font_size": 8,
                "bold": true,
                "text": "model. Transp. Res. Part F Trafﬁc Psychol. Behav. 9(1), 15–27"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "(2006)"
            }
        },
        "paragraph_27": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "30. Vilarinho, C.; Tavares, J.P.; Rossetti, R.J.: Intelligent trafﬁc lights:"
            },
            "line_1": {
                "font_size": 8,
                "bold": true,
                "text": "green time period negotiation. Transp. Res. Procedia 22, 325–334"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "(2017)"
            }
        },
        "paragraph_28": {
            "line_0": {
                "font_size": 8,
                "bold": true,
                "text": "31. Watkins, C.J.; Dayan, P.: Q-learning. Mach. Learn. 8(3–4), 279–"
            }
        },
        "paragraph_29": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "292 (1992)"
            }
        },
        "paragraph_30": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "32. Wiering, M.: Multi-agent reinforcement learning for trafﬁc light"
            }
        },
        "paragraph_31": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "control. In: ICML, pp. 1151–1158 (2000)"
            }
        },
        "paragraph_32": {
            "line_0": {
                "font_size": 8,
                "bold": false,
                "text": "33. Xinhai, X.; Lunhui, X.: Trafﬁc signal control agent interaction"
            },
            "line_1": {
                "font_size": 8,
                "bold": false,
                "text": "model based on game theory and reinforcement learning. In:"
            },
            "line_2": {
                "font_size": 8,
                "bold": false,
                "text": "International Forum on Computer Science-Technology and Appli-"
            },
            "line_3": {
                "font_size": 8,
                "bold": false,
                "text": "cations, vol. 1, pp. 164–168. IEEE (2009)"
            }
        },
        "paragraph_33": {
            "line_0": {
                "font_size": 15,
                "bold": false,
                "text": "123"
            }
        },
        "paragraph_34": {},
        "paragraph_35": {}
    }
}